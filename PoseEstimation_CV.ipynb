{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install tensorflow\n",
        "\n",
        "!pip3 install tf_pose\n",
        "\n",
        "!sudo pip install numpy --upgrade --ignore-installed\n",
        "\n",
        "import numpy\n",
        "numpy.version.version\n",
        "\n",
        "!pip3 install numpy==1.15.1"
      ],
      "metadata": {
        "id": "k1q37nYKBOKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.version.version"
      ],
      "metadata": {
        "id": "fCFbmAlrLzPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "import cv2\n",
        "import math\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tf_pose import common\n",
        "from tf_pose.estimator import TfPoseEstimator\n",
        "from tf_pose.networks import get_graph_path, model_wh"
      ],
      "metadata": {
        "id": "7HuQ9P-KBjxm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger('TfPoseEstimatorRun')\n",
        "logger.handlers.clear()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "cJao102QHsph"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model='mobilenet_thin'\n",
        "resize='432x368'\n",
        "w, h = model_wh(resize)\n",
        "if w == 0 or h == 0:\n",
        "    e = TfPoseEstimator(get_graph_path(model), target_size=(432, 368))\n",
        "else:\n",
        "    e = TfPoseEstimator(get_graph_path(model), target_size=(w, h))"
      ],
      "metadata": {
        "id": "FH1MMviWHrf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose Estimation, Key point estimation"
      ],
      "metadata": {
        "id": "_Zr6IshSthJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading and Plotting the image\n",
        "image_path = 'Image2.png'\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image)\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "6UDGqvTKHrWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Image array:',image)\n",
        "print('Image Shape:', image.shape)"
      ],
      "metadata": {
        "id": "0YieuU6uNsvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_plt(image, axis=False, grid=False, showBG = True):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    if showBG:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image);\n",
        "    if grid == True:\n",
        "        plt.grid();\n",
        "    if axis == False:       \n",
        "        plt.axis('off');"
      ],
      "metadata": {
        "id": "Wd4-_NtQN7XU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Function for showing the image\n",
        "image_path = 'Image2.png'\n",
        "img_plt(cv2.imread(image_path), axis=True, grid=True)"
      ],
      "metadata": {
        "id": "jodhYo3LrQou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change image for further procassing\n",
        "image = common.read_imgfile(image_path, None, None)\n",
        "\n",
        "# Nose = 0\n",
        "# Neck = 1\n",
        "# RShoulder = 2\n",
        "# RElbow = 3\n",
        "# RWrist = 4\n",
        "# LShoulder = 5\n",
        "# LElbow = 6\n",
        "# LWrist = 7\n",
        "# RHip = 8\n",
        "# RKnee = 9\n",
        "# RAnkle = 10\n",
        "# LHip = 11\n",
        "# LKnee = 12\n",
        "# LAnkle = 13\n",
        "# REye = 14\n",
        "# LEye = 15\n",
        "# REar = 16\n",
        "# LEar = 17\n",
        "# Background = 18"
      ],
      "metadata": {
        "id": "CFngfyauOF-A"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Image array:',image)\n",
        "print('Image Shape:', image.shape)"
      ],
      "metadata": {
        "id": "f7_Q92eIA7j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# e.inference method gives keypoints coordinates\n",
        "humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
        "print('Heatmat Shape:',e.heatMat.shape)\n",
        "print('Heatmat:',e.heatMat)\n",
        "\n",
        "print(humans)"
      ],
      "metadata": {
        "id": "A1uPKljLTGuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Heatmap\n",
        "max_prob = np.amax(e.heatMat[:, :, :-1], axis=2)\n",
        "plt.imshow(max_prob)\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "jGKVJK6gxLqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Heatmap superimposed on image\n",
        "plt.figure(figsize=(15,8))\n",
        "bgimg = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
        "bgimg = cv2.resize(bgimg, (e.heatMat.shape[1], e.heatMat.shape[0]), interpolation=cv2.INTER_AREA)\n",
        "plt.imshow(bgimg, alpha=0.5)\n",
        "plt.imshow(max_prob, alpha=0.5)\n",
        "plt.colorbar()\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "T4Xz-vRfxPR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum probability pairs\n",
        "print('PAF matrix shape',e.pafMat.shape) \n",
        "\n",
        "tmp2 = e.pafMat.transpose((2, 0, 1))\n",
        "tmp2_odd = np.amax(np.absolute(tmp2[::2, :, :]), axis=0)\n",
        "tmp2_even = np.amax(np.absolute(tmp2[1::2, :, :]), axis=0)\n",
        "\n",
        "fig = plt.figure(figsize=(20,15))\n",
        "\n",
        "a = fig.add_subplot(2, 2, 3)\n",
        "a.set_title('Vectormap-x')\n",
        "plt.imshow(tmp2_odd, alpha=0.5)\n",
        "plt.colorbar()\n",
        "\n",
        "a = fig.add_subplot(2, 2, 4)\n",
        "a.set_title('Vectormap-y')\n",
        "plt.imshow(tmp2_even, alpha=0.5)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cnQpar1kxaiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)"
      ],
      "metadata": {
        "id": "BDeQ4oj2xgFT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_plt(image, axis=True, grid=True)"
      ],
      "metadata": {
        "id": "U1vma9Oxxk7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the skeleton\n",
        "image = common.read_imgfile(image_path, None, None)\n",
        "humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
        "black_background = np.zeros(image.shape)\n",
        "skeleton = TfPoseEstimator.draw_humans(black_background, humans, imgcopy=False)\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.imshow(skeleton);\n",
        "plt.grid();      \n",
        "plt.axis('off');\n",
        "\n",
        "##"
      ],
      "metadata": {
        "id": "CHXoIPyBxnlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints = str(str(str(humans[0]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
        "len(keypoints)"
      ],
      "metadata": {
        "id": "EzRGJ894x3xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints"
      ],
      "metadata": {
        "id": "KfnWIGT_6ZbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NEW PART1\n",
        "index_array = str(humans[0]).split('BodyPart:')[1:]\n",
        "\n",
        "new_index_array=[]\n",
        "for i in index_array:\n",
        "   new_index_array.append(i.split('-')[0])\n",
        "\n",
        "new_index_array = list(map(int, new_index_array))\n",
        "new_index_array"
      ],
      "metadata": {
        "id": "ahpbhuzW5Myd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keypoints list index-wise\n",
        "keypoints_list=[]\n",
        "j=0\n",
        "for i in range (17):\n",
        "\n",
        "  if (i==int(new_index_array[j])):\n",
        "    pnt = keypoints[j][-11:-1]\n",
        "    pnt = tuple(map(float, pnt.split(', ')))\n",
        "    keypoints_list.append(pnt)\n",
        "    j=j+1\n",
        "\n",
        "  else:\n",
        "    keypoints_list.append((0,0))  \n",
        "\n",
        "print(keypoints_list)"
      ],
      "metadata": {
        "id": "ZZHlKbjf5toy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving original key points coordinates\n",
        "keypts_array = np.array(keypoints_list)\n",
        "keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
        "keypts_array = keypts_array.astype(int)\n",
        "keypts_array"
      ],
      "metadata": {
        "id": "vAcwnZ6TyCVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Angle calculation using keypts_array (Kinematic Feature Extraction)"
      ],
      "metadata": {
        "id": "--byWclPMArT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Angle (11,1,5) Left Trunk Angle\n",
        "import numpy as np\n",
        "\n",
        "a = keypts_array[11]\n",
        "b = keypts_array[1]\n",
        "c = keypts_array[5]\n",
        "\n",
        "ba = a - b\n",
        "bc = c - b\n",
        "\n",
        "cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "angle = np.arccos(cosine_angle)\n",
        "ang_deg = np.degrees(angle)\n",
        "\n",
        "print(ang_deg)"
      ],
      "metadata": {
        "id": "qTzlBIXFL_t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Angle (2,1,8) Right Trunk Angle\n",
        "import numpy as np\n",
        "\n",
        "a = keypts_array[2]\n",
        "b = keypts_array[1]\n",
        "c = keypts_array[8]\n",
        "\n",
        "ba = a - b\n",
        "bc = c - b\n",
        "\n",
        "cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "angle = np.arccos(cosine_angle)\n",
        "ang_deg = np.degrees(angle)\n",
        "\n",
        "print(ang_deg)"
      ],
      "metadata": {
        "id": "rtVI3V-DO6zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distance bw ref point and rankle keypoint (#10) calculation for the frontal frame done"
      ],
      "metadata": {
        "id": "DXTM3e9hB5h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "kpt10 = keypts_array[10]\n",
        "refpt = np.array([2150, 2000])\n",
        "\n",
        "dist = math.dist(kpt10, refpt)\n",
        "\n",
        "print(dist)"
      ],
      "metadata": {
        "id": "s7mBhZVPBvQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Angle (8,9,10) Right Knee Angle - Lateral frame\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = keypts_array[8]\n",
        "b = keypts_array[9]\n",
        "c = keypts_array[10]\n",
        "\n",
        "ba = a - b\n",
        "bc = c - b\n",
        "\n",
        "cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "angle = np.arccos(cosine_angle)\n",
        "ang_deg = np.degrees(angle)\n",
        "\n",
        "print(ang_deg)"
      ],
      "metadata": {
        "id": "XMMlZ_IfO_pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Angle (9,8,1) Right Hip Angle - Lateral frame\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = keypts_array[9]\n",
        "b = keypts_array[8]\n",
        "c = keypts_array[1]\n",
        "\n",
        "ba = a - b\n",
        "bc = c - b\n",
        "\n",
        "cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "angle = np.arccos(cosine_angle)\n",
        "ang_deg = np.degrees(angle)\n",
        "\n",
        "print(ang_deg)"
      ],
      "metadata": {
        "id": "JVVL9-5oh4V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thresholding on above values help with the classification part"
      ],
      "metadata": {
        "id": "AGWWGjLQt7BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def human_pose(image_path, showBG = True):\n",
        "    image = common.read_imgfile(image_path, None, None)\n",
        "  \n",
        "    if image is None:\n",
        "        logger.error('Image can not be read, path=%s' % image)\n",
        "        sys.exit(-1)\n",
        "\n",
        "    t = time.time()\n",
        "    \n",
        "    humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
        "    elapsed = time.time() - t\n",
        "\n",
        "    if showBG == False:\n",
        "        image = np.zeros(image.shape)\n",
        "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
        "    return image, humans"
      ],
      "metadata": {
        "id": "7ccik1CKpizx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keypoints_plt(image, hum, human=1, color='orange', showBG = True):\n",
        "    if human == 0: human = 1\n",
        "    num_hum = len(hum)\n",
        "    keypoints = str(str(str(hum[human-1]).split('BodyPart:')[1:]).split('-')).split(' score=')\n",
        "    keypoints_list=[]\n",
        "    for i in range (len(keypoints)-1): \n",
        "        pnt = keypoints[i][-11:-1]\n",
        "        pnt = tuple(map(float, pnt.split(', ')))\n",
        "        keypoints_list.append(pnt)\n",
        "\n",
        "    keypts_array = np.array(keypoints_list)\n",
        "    keypts_array = keypts_array*(image.shape[1],image.shape[0])\n",
        "    keypts_array = keypts_array.astype(int)\n",
        "    keypts_array\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.axis([0, image.shape[1], 0, image.shape[0]])  \n",
        "    plt.scatter(*zip(*keypts_array), s=200, color=color, alpha=0.6)\n",
        "    if showBG:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)      \n",
        "    plt.imshow(image)\n",
        "    ax=plt.gca() \n",
        "    ax.set_ylim(ax.get_ylim()[::-1]) \n",
        "    ax.xaxis.tick_top() \n",
        "    plt.title('Keypoints Person [{}] from {} humans detected\\n'.format(human, num_hum))\n",
        "    plt.grid();\n",
        "\n",
        "    for i, txt in enumerate(keypts_array):\n",
        "        ax.annotate(i, (keypts_array[i][0]-5, keypts_array[i][1]+5))\n",
        "            \n",
        "    return keypts_array"
      ],
      "metadata": {
        "id": "Qbmbty8Lpimc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'Image2.png'\n",
        "img, hum = human_pose(image_path, showBG = True)\n",
        "img_plt(img, axis=True, grid=True)\n",
        "\n",
        "hum"
      ],
      "metadata": {
        "id": "rrhMA0uayneW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'Image2.png'\n",
        "img, hum = human_pose(image_path, showBG=False)\n",
        "keypoints = keypoints_plt(img, hum, showBG=False)"
      ],
      "metadata": {
        "id": "_lrVwq1bza8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting code for frame-wise analysis\n",
        "import cv2\n",
        "  \n",
        "def FrameCapture0(path):\n",
        "  \n",
        "    vidObj = cv2.VideoCapture(path)\n",
        "    count = 0\n",
        "    success = 1\n",
        "  \n",
        "    while success:\n",
        "        success, image = vidObj.read()\n",
        "        cv2.imwrite(\"/content/sample_data/s3/frame%d.jpg\" % count, image)\n",
        "        count += 1"
      ],
      "metadata": {
        "id": "-wCnnS9uNesa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/sample_data/s3.zip /content/sample_data/s3"
      ],
      "metadata": {
        "id": "EV8kc4KnPWTA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}